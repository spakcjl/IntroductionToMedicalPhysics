---
title: "Signal Processing & Systems in Medical Physics"
author: "Graduate Medical Physics Program"
date: "`r Sys.Date()`"
output:
  powerpoint_presentation:
    slide_level: 3
---

```{r setup, include=FALSE}
# It's a good practice to set up the environment in the first chunk.
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)

# Load necessary packages
library(ggplot2)
library(dplyr)
library(reticulate)
library(patchwork)
library(magick)
library(reshape2)
library(ggforce)

# Configure reticulate to use the system's default Python
# This avoids issues with virtual environments in this context.
tryCatch({
  use_python(Sys.which("python3"), required = TRUE)
}, error = function(e) {
  message("Python3 not found or reticulate failed. Python chunks will not work.")
  message(e)
})
```

## Module 1: Deterministic Systems



::: notes
Welcome to the first module. We will establish the fundamental mathematical and conceptual toolkit for signal and systems analysis. Pay close attention to the definitions, as they are the building blocks for everything that follows.

:::

### Introduction to Signals

- **What is a signal?** A signal is a function that conveys information about a phenomenon.
- In medical physics, signals are representations of physical quantities.


### Introduction to Signals: Examples

- Voltage from a detector
- X-ray intensity pattern
- Magnetic resonance signal over time




::: notes
A signal is just a function. For example, the temperature in this room over the course of the day is a signal. An MR signal is a function of time. An image is a function of spatial coordinates.

:::

### Continuous vs. Discrete Signals

- **Continuous-Time Signal:** Defined for all points in time. Represented as `x(t)`.
- **Discrete-Time Signal:** Defined only at specific, discrete points in time. Represented as `x[n]`.


### Continuous vs. Discrete Signals

- This distinction is crucial for understanding digital acquisition and processing.




::: notes
Think of a continuous signal as a smooth, unbroken line, like a wave. A discrete signal is a series of individual points, like readings taken every second. Computers can only work with discrete signals.

:::

### Visualization: Continuous vs. Discrete

```{r continuous_discrete_plot, echo=FALSE, fig.cap="A continuous sine wave."}
library(ggplot2)
library(dplyr)

# Continuous Signal
t_cont <- seq(0, 2 * pi, length.out = 500)
x_cont <- sin(t_cont)
df_cont <- data.frame(Time = t_cont, Amplitude = x_cont)

# Plot
ggplot(df_cont, aes(x = Time, y = Amplitude)) +
  geom_line() +
  ggtitle("Continuous Signal: x(t) = sin(t)") +
  theme_minimal() +
  labs(x = "Time (t)", y = "Amplitude")
```

### Visualization: Continuous vs. Discrete
```{r discrete_plot, echo=FALSE, fig.cap="A discrete sine wave."}
# Discrete Signal
n_discrete <- 0:15
t_discrete <- n_discrete * (2 * pi / 16)
x_discrete <- sin(t_discrete)
df_discrete <- data.frame(Time = t_discrete, Amplitude = x_discrete)

# Plot
ggplot(df_discrete, aes(x = Time, y = Amplitude)) +
  geom_point(size = 3, color = "red") +
  geom_segment(aes(xend = Time, yend = 0), linetype = "dashed") +
  ggtitle("Discrete Signal: x[n] = sin(2πn/16)") +
  theme_minimal() +
  labs(x = "Sample (n)", y = "Amplitude")
```



::: notes
On the left, we see the smooth `sin(t)`. On the right, we see samples of that same function. The process of converting from continuous to discrete is called **sampling**, a topic we will cover in great detail.

:::

### Standard Functions in Signal Processing

- We use a set of "building block" functions to model and analyze more complex signals.
- Understanding these is essential for a deep intuition of systems.


### Standard Functions in Signal Processing

- Key Functions:
  - The Rectangular Function (Rect)


### Standard Functions in Signal processing
- Key Functions:
  - The Sinc Function


### Standard Functions in Signal processing
- Key Functions:
  - The Dirac Delta Function


### Standard Functions in Signal processing
- Key Functions:
  - The Comb Function



::: notes
These functions are like the primary colors of signal processing. We can combine them to create almost any signal we need.

:::

### The Rectangular Function: Math

The Rectangular function, `rect(t)`, is a simple but vital function.

$$
\text{rect}(t) =
\begin{cases}
      1 & |t| \le 1/2 \\
      0 & |t| > 1/2
\end{cases}
$$

### The Rectangular Function: Visualization
```{r rect_function_plot, echo=FALSE, fig.cap="The Rectangular Function"}
rect_func <- function(t) {
  return(ifelse(abs(t) <= 0.5, 1, 0))
}
t <- seq(-2, 2, length.out = 1000)
rect_data <- data.frame(Time = t, Amplitude = rect_func(t))

ggplot(rect_data, aes(x = Time, y = Amplitude)) +
  geom_line(size = 1) +
  ggtitle("The Rectangular Function") +
  theme_minimal() +
  ylim(0, 1.2)
```



::: notes
A perfect box centered at zero with a width of 1. This function can model a pulse, a pixel, or an imaging aperture.

:::

### The Sinc Function: Math

The Sinc function is the Fourier Transform of the Rect function. It is incredibly important in imaging and sampling theory.

$$
\text{sinc}(t) = \frac{\sin(\pi t)}{\pi t}
$$

### The Sinc Function: Visualization
```{r sinc_function_plot, echo=FALSE, fig.cap="The Sinc Function"}
sinc_func <- function(t) {
  # Handle the t=0 case where the formula is undefined
  result <- ifelse(t == 0, 1, sin(pi * t) / (pi * t))
  return(result)
}
t_sinc <- seq(-5, 5, length.out = 2000)
sinc_data <- data.frame(Time = t_sinc, Amplitude = sinc_func(t_sinc))

ggplot(sinc_data, aes(x = Time, y = Amplitude)) +
  geom_line(size = 1) +
  geom_hline(yintercept = 0, linetype="dashed") +
  ggtitle("The Sinc Function") +
  theme_minimal()
```



::: notes
Notice the central lobe and the decaying side lobes. The zero crossings are at integer values of t. This shape is fundamental to understanding image resolution and aliasing.

:::

### Pop Quiz!

What is the value of `rect(1)`?

A) 1
B) 0.5
C) 0
D) Undefined



::: notes
Answer: C) 0. The function is only 1 when the absolute value of t is less than or equal to 0.5. Since 1 > 0.5, the value is 0.

:::

### The Dirac Delta Function: Concept

The Dirac Delta, `δ(t)`, is a "generalized function." It's not a true function in the classical sense.

- It is infinitely tall.
- It is infinitesimally narrow.
- Its total area is exactly 1.

$$
\delta(t) = 0 \text{ for } t \ne 0, \quad \text{and} \quad \int_{-\infty}^{\infty} \delta(t) dt = 1
$$

### The Dirac Delta Function: Visualization
```{r dirac_delta_plot, echo=FALSE, fig.cap="Conceptual visualization of the Dirac Delta function."}
ggplot() +
  geom_segment(aes(x = 0, y = 0, xend = 0, yend = 1),
               arrow = arrow(length = unit(0.5, "cm")), size = 1.5) +
  geom_hline(yintercept = 0) +
  xlim(-2, 2) +
  ylim(0, 1.2) +
  ggtitle("The Dirac Delta Function δ(t)") +
  xlab("t") +
  ylab("") +
  theme_minimal() +
  theme(axis.text.y=element_blank(), axis.ticks.y=element_blank())
```



::: notes
Since the delta function is an idealization, we can't plot it literally. We represent it as an arrow at t=0 to signify an impulse with an area of 1 concentrated at that single point.

:::

### The Dirac Delta: Sifting Property

The most important property of the delta function is the **sifting property**. It "pulls out" the value of a function at a single point.

$$
\int_{-\infty}^{\infty} f(t) \delta(t - t_0) dt = f(t_0)
$$



::: notes
This property is the foundation of sampling theory. Multiplying a signal by a delta function is like taking a perfect, instantaneous sample of that signal at that exact point.

:::

### The Comb Function (Shah Function)

The Comb function is an infinite series of Dirac delta functions spaced at regular intervals.

$$
\text{comb}(t) = \sum_{n=-\infty}^{\infty} \delta(t - nT)
$$

- It is also known as the Shah function or an impulse train.
- It is the mathematical model for the process of sampling.

### The Comb Function: Visualization
```{r comb_function_plot, echo=FALSE, fig.cap="Conceptual visualization of the Comb function."}
comb_data <- data.frame(x = -3:3)

ggplot(comb_data, aes(x=x)) +
  geom_segment(aes(xend = x, y = 0, yend = 1),
               arrow = arrow(length = unit(0.4, "cm")), size = 1) +
  geom_hline(yintercept = 0) +
  xlim(-4, 4) +
  ylim(0, 1.2) +
  ggtitle("The Comb Function") +
  xlab("t") +
  ylab("") +
  theme_minimal() +
  theme(axis.text.y=element_blank(), axis.ticks.y=element_blank())
```



::: notes
Imagine a comb's teeth; each tooth is a delta function. When we multiply a continuous signal by a comb function, we are left with a series of discrete samples—the value of the signal at the location of each "tooth."

:::

### Sampling and Aliasing

- When we convert a continuous signal to a discrete one, we are **sampling** it.
- How often do we need to sample to perfectly capture the signal?


### The Nyquist-Shannon Sampling Theorem

- **Theorem:** A continuous signal can be perfectly reconstructed from its samples if the sampling frequency (`fs`) is greater than twice the highest frequency (`fmax`) in the signal.
- `fs > 2 * fmax`
- The frequency `2 * fmax` is called the **Nyquist Rate**.


### Aliasing: The Consequence of Undersampling

- If you sample below the Nyquist rate (`fs < 2 * fmax`), you get **aliasing**.
- A high frequency in the original signal will masquerade as a lower frequency in the sampled version.
- This is a form of irreversible information loss.


### Aliasing: Visualization Code

```{r aliasing_code, echo=TRUE}
# Define a high-frequency signal
f_high <- 10 # Hz
t <- seq(0, 1, length.out = 1000)
signal_cont <- sin(2 * pi * f_high * t)

# Case 1: Adequate Sampling (fs > 2 * fmax)
fs_good <- 25 # Sampling freq > 2 * 10
t_good <- seq(0, 1, by = 1/fs_good)
signal_good <- sin(2 * pi * f_high * t_good)

# Case 2: Undersampling (fs < 2 * fmax)
fs_bad <- 12 # Sampling freq < 2 * 10
t_bad <- seq(0, 1, by = 1/fs_bad)
signal_bad <- sin(2 * pi * f_high * t_bad)
# The aliased frequency will appear at |f_high - fs_bad| = |10 - 12| = 2 Hz
aliased_signal_cont <- sin(2 * pi * 2 * t)
```

### Aliasing: Adequate Sampling

```{r aliasing_plot_good, echo=FALSE, fig.cap="A 10 Hz signal sampled at 25 Hz. The samples still capture the wave's shape."}
df_cont <- data.frame(Time = t, Value = signal_cont)
df_good <- data.frame(Time = t_good, Value = signal_good)

ggplot() +
  geom_line(data = df_cont, aes(x = Time, y = Value), color = "gray") +
  geom_point(data = df_good, aes(x = Time, y = Value), color = "red", size = 3) +
  ggtitle("Adequate Sampling (fs > 2*fmax)") +
  theme_minimal()
```

### Aliasing: Undersampling

```{r aliasing_plot_bad, echo=FALSE, fig.cap="A 10 Hz signal sampled at 12 Hz. The samples now trace a 2 Hz wave."}
df_bad <- data.frame(Time = t_bad, Value = signal_bad)
df_aliased <- data.frame(Time = t, Value = aliased_signal_cont)

ggplot() +
  geom_line(data = df_cont, aes(x = Time, y = Value), color = "gray", linetype = "dashed") +
  geom_line(data = df_aliased, aes(x = Time, y = Value), color = "blue") +
  geom_point(data = df_bad, aes(x = Time, y = Value), color = "red", size = 3) +
  ggtitle("Undersampling (fs < 2*fmax)") +
  labs(subtitle = "Original 10 Hz wave (gray) appears as a 2 Hz wave (blue)") +
  theme_minimal()
```

### LSI Systems

- **System:** A process that transforms an input signal `x(t)` into an output signal `y(t)`.


### LSI Systems
- **LSI System:** A system that is both **Linear** and **Shift-Invariant**.


### LSI Systems
- These properties make systems much easier to analyze.


### LSI Systems
- Most imaging systems are approximated as LSI systems.



::: notes
LSI systems are the cornerstone of this field. If we know a system is LSI, we can predict its output for any input, simply by knowing its response to a single impulse.

:::

### Linearity

- A system is **linear** if it obeys the principle of superposition.


### Linearity
1.  **Homogeneity:** `T{a * x(t)} = a * T{x(t)}`
    - (Scaling the input scales the output by the same amount)


### Linearity
2.  **Additivity:** `T{x1(t) + x2(t)} = T{x1(t)} + T{x2(t)}`
    - (The response to a sum of inputs is the sum of their individual responses)



::: notes
In simple terms: if you double the input, you double the output. If you add two inputs together, the output is the sum of the outputs you would have gotten from each one separately. No surprises.

:::

### Shift-Invariance (or Time-Invariance)

- A system is **shift-invariant** if a shift in the input signal causes an identical shift in the output signal.


### Shift-Invariance (or Time-Invariance)
- If `y(t) = T{x(t)}`, then `y(t - t_0) = T{x(t - t_0)}`.


### Shift-Invariance (or Time-Invariance)
- The behavior of the system does not change over time or space.




::: notes
This is a crucial assumption. It means that the rules of the system don't change depending on when or where you apply the input. An X-ray system should produce the same image of a phantom today as it did yesterday (assuming the same technique).

:::

### Discussion Question

Is the financial process of adding 5% interest to a bank account a **linear** system? Why or why not?




::: notes
Let's analyze. Let the transformation T be applying interest.
- Homogeneity: T{a * x} = 1.05 * (a*x). And a * T{x} = a * (1.05 * x). These are equal. Homogeneity holds.
- Additivity: T{x1 + x2} = 1.05 * (x1 + x2). And T{x1} + T{x2} = 1.05*x1 + 1.05*x2. These are equal. Additivity holds.
- Yes, it is a linear system.

:::

### Convolution: The Core of LSI Systems

- Convolution is the mathematical operation that describes the output of an LSI system.


### Convolution: The Core of LSI Systems
- Every LSI system is completely characterized by its **Impulse Response Function (IRF)**, `h(t)`.


### Convolution: The Core of LSI Systems
- The output `y(t)` is the convolution of the input `x(t)` with the system's IRF `h(t)`.



::: notes
This is the single most important concept for LSI systems. If you know the system's response to a perfect impulse (the IRF), you can calculate its response to literally any input.

:::

### Convolution: The Math

The convolution integral is defined as:

$$
y(t) = x(t) * h(t) = \int_{-\infty}^{\infty} x(\tau) h(t - \tau) d\tau
$$

- `*` denotes the convolution operation.
- `τ` is a dummy variable of integration.



::: notes
This equation looks intimidating, but it has a very intuitive meaning. It's a "weighted average" of the input signal, where the weighting function is the system's impulse response, flipped and shifted.

:::

### Convolution: The Intuition

Think of `h(t)` as a "smearing" or "blurring" function. The convolution integral slides the flipped `h(-τ)` along the input `x(τ)` and, at each position `t`, calculates the overlapping area.


### Convolution: The Intuition
1.  **Flip:** Take the impulse response `h(τ)` and flip it to get `h(-τ)`.
2.  **Shift:** Shift it by `t`.


### Convolution: The Intuition
3.  **Multiply:** Multiply the input `x(τ)` by the shifted, flipped `h(t - τ)`.
4.  **Integrate:** Calculate the area under the product. This area is the value of the output `y(t)` at that specific `t`.




::: notes
This "flip, shift, multiply, integrate" process is the mechanical-graphical way to understand convolution. We will visualize this process to make it clearer.

:::

### Convolution: Graphical Example Step 1
- We start with an input signal `x(t)` (a Rect function) and an impulse response `h(t)` (a triangle function).

### Convolution: Graphical Example Step 1 (cont.)
```{r conv_viz_setup, echo=FALSE}
x_func <- function(t) ifelse(t >= 0 & t <= 2, 1, 0)
h_func <- function(t) ifelse(t >= 0 & t <= 1, t, ifelse(t > 1 & t <= 2, 2 - t, 0))
t_viz <- seq(-1, 5, length.out=1000)
df_x <- data.frame(t=t_viz, val=x_func(t_viz), type="x(t)")
df_h <- data.frame(t=t_viz, val=h_func(t_viz), type="h(t)")

ggplot() +
  geom_line(data=df_x, aes(x=t, y=val, color=type)) +
  geom_line(data=df_h, aes(x=t, y=val, color=type)) +
  ggtitle("Input Signal and Impulse Response") + theme_minimal()
```

### Convolution: Graphical Example Step 2
- We "flip" the impulse response to get `h(-τ)`.
- The integral is `y(t) = ∫ x(τ) h(t - τ) dτ`. We plot for a specific time `t`, say `t=0.5`.

### Convolution: Graphical Example Step 2 (cont.)
```{r conv_viz_flip, echo=FALSE}
t_val <- 0.5
h_flipped_shifted <- function(tau) h_func(t_val - tau)
df_h_flip <- data.frame(t=t_viz, val=h_flipped_shifted(t_viz), type=paste0("h(",t_val,"-τ)"))
df_prod <- data.frame(t=t_viz, val=x_func(t_viz) * h_flipped_shifted(t_viz), type="product")

ggplot() +
  geom_line(data=df_x, aes(x=t, y=val, color=type)) +
  geom_line(data=df_h_flip, aes(x=t, y=val, color=type)) +
  geom_area(data=df_prod, aes(x=t, y=val), fill="purple", alpha=0.5) +
  ggtitle("Flipping, Shifting, and Multiplying") + theme_minimal()
```

### Convolution: Graphical Example Step 2 (cont.)
- The purple area is the product `x(τ)h(t-τ)`. The integral of this area is the value of the convolution `y(t)` at `t=0.5`.

### Convolution Example: Denoising Code
Let's convolve a noisy signal with a simple averaging kernel (a rect function) to smooth it out.

### Convolution Example: Denoising Code (cont.)
```{r convolution_code, echo=TRUE}
# 1. Create a noisy signal
t_conv <- seq(0, 10, length.out = 500)
signal <- sin(t_conv) + 0.1 * cos(t_conv * 20) # Base signal + high-freq noise
noise <- rnorm(500, mean = 0, sd = 0.2)
noisy_signal <- signal + noise

df_noisy <- data.frame(Time = t_conv, Value = noisy_signal, Type = "Noisy")

# 2. Perform convolution in the discrete domain (moving average)
# R's 'filter' function is a way to do 1D convolution
kernel <- rep(1/11, 11) # A simple 11-point averaging kernel
smoothed_signal <- stats::filter(noisy_signal, kernel, sides = 2)

df_smooth <- data.frame(Time = t_conv, Value = smoothed_signal, Type = "Smoothed")

# Combine for plotting
df_conv <- rbind(df_noisy, df_smooth)
```



::: notes
Here we create a signal with some high-frequency noise. Then we define a simple averaging kernel. The `filter` function in R performs a convolution, effectively applying a moving average to our noisy signal.

:::

### Convolution Example: Denoising Visualization
```{r convolution_plot, echo=FALSE, fig.cap="A noisy signal before and after convolution with a smoothing kernel."}
ggplot(df_conv, aes(x = Time, y = Value, color = Type)) +
  geom_line(size = 1) +
  ggtitle("Signal Denoising via Convolution") +
  theme_minimal() +
  scale_color_manual(values = c("Noisy" = "gray", "Smoothed" = "red"))
```



::: notes
The result is clear. The red "Smoothed" signal is a less noisy version of the original gray signal. The convolution has averaged out the rapid fluctuations, an example of low-pass filtering.

:::

### Fourier Analysis

- A revolutionary idea: **Any signal can be represented as a sum of sines and cosines.**
- The **Fourier Transform (FT)** is the mathematical tool that decomposes a signal from its "time domain" into its constituent frequencies in the "frequency domain."




::: notes
Fourier analysis is like taking a musical chord and figuring out the individual notes that make it up. It's one of the most powerful tools in all of science and engineering.

:::

### The Fourier Transform: Math

The 1D Forward Fourier Transform:

$$
X(k) = \mathcal{F}\{x(t)\} = \int_{-\infty}^{\infty} x(t) e^{-i 2\pi k t} dt
$$

- `x(t)`: The signal in the time domain.
- `X(k)`: The signal in the frequency domain.
- `k`: Represents frequency.



::: notes
This is the equation that takes us from the time domain to the frequency domain. The `exp(-i*2*pi*k*t)` term is Euler's formula, which represents sines and cosines. This integral measures "how much" of each frequency `k` is present in the signal `x(t)`.

:::

### The Fourier Transform: Variable Breakdown

$$ X(k) = \int_{-\infty}^{\infty} x(t) e^{-i 2\pi k t} dt $$

- **`X(k)`**: The output. A complex-valued function representing the frequency spectrum. Its magnitude tells you the amplitude of each frequency, and its phase tells you the alignment.


### The Fourier Transform: Variable Breakdown
- **`x(t)`**: The input signal as a function of time (or space).
- **`k`**: The frequency variable.


### The Fourier Transform: Variable Breakdown
- **`t`**: The time variable (or space).
- **`i`**: The imaginary unit, `sqrt(-1)`.



::: notes
The output `X(k)` is complex, which can be tricky. For visualization, we almost always look at the magnitude, `|X(k)|`, which is called the amplitude spectrum.

:::

### The Fourier Transform: Intuition

The FT is a "frequency machine."

- You put a time-domain signal `x(t)` in.
- It gives you a frequency-domain spectrum `X(k)` out.
- A peak in `X(k)` at `k=k0` means the original signal `x(t)` contained a strong sinusoidal component at the frequency `k0`.



::: notes
Think of it as a prism for signals. A prism takes in white light (a complex signal) and splits it into its constituent colors (the frequency spectrum). The Fourier Transform does the same for any signal.

:::

### FT Example: Sine Wave Code
```{r ft_sine_code, echo=TRUE}
# Create a simple sine wave
fs <- 100 # Sampling frequency
t_ft <- seq(0, 1, length.out = fs)
freq <- 5 # 5 Hz
x_sine <- sin(2 * pi * freq * t_ft)

# Calculate the Fast Fourier Transform (FFT)
fft_result <- fft(x_sine)
fft_magnitude <- Mod(fft_result)

# Create frequency axis for plotting
freq_axis <- seq(0, fs, length.out = fs)

df_fft <- data.frame(Frequency = freq_axis, Magnitude = fft_magnitude)
```



::: notes
Here we create a pure 5 Hz sine wave. We then use R's `fft` function, which is a fast algorithm for computing the Discrete Fourier Transform. We calculate the magnitude for visualization.

:::

### FT Example: Sine Wave Visualization
```{r ft_sine_plot, echo=FALSE, fig.cap="Time domain and Frequency domain of a 5 Hz sine wave."}
p_time <- ggplot(data.frame(Time=t_ft, Amplitude=x_sine), aes(x=Time, y=Amplitude)) +
  geom_line() + ggtitle("Time Domain: 5 Hz Sine Wave")

# Plot only the first half of the spectrum (due to symmetry)
p_freq <- ggplot(df_fft[1:(fs/2), ], aes(x = Frequency, y = Magnitude)) +
  geom_line() +
  ggtitle("Frequency Domain (Magnitude)") +
  labs(x = "Frequency (Hz)")

p_time + p_freq
```



::: notes
On the left is our signal. On the right is its Fourier spectrum. Notice the strong, sharp peak at exactly 5 Hz, just as we expected. The FT correctly identified the frequency content of the signal. The second peak near 95Hz is its alias due to Nyquist theorem.

:::

### The 2D Fourier Transform

The concept extends to 2D signals, like images.

$$
F(k_x, k_y) = \int_{-\infty}^{\infty}\int_{-\infty}^{\infty} f(x,y) e^{-i 2\pi (k_x x + k_y y)} dx dy
$$

- `f(x,y)`: The 2D image.
- `F(kx, ky)`: The 2D frequency spectrum.


### The 2D Fourier Transform
- `kx, ky`: Spatial frequencies in the x and y directions.



::: notes
Instead of temporal frequency, we now have spatial frequencies. `kx` represents how fast the image intensity changes in the x-direction, and `ky` for the y-direction. High spatial frequencies correspond to sharp edges, and low frequencies correspond to smooth areas.

:::

### 2D FT Example: 2D Rect Code
```{r 2d_ft_code, echo=TRUE}
# Create a 2D Rect function (a white square on a black background)
matrix_size <- 128
img_matrix <- matrix(0, nrow = matrix_size, ncol = matrix_size)
center <- matrix_size / 2
width <- 16
img_matrix[(center - width/2):(center + width/2), (center - width/2):(center + width/2)] <- 1

# Calculate the 2D FFT
fft_2d_result <- fft(img_matrix)

# For visualization, we want to see the magnitude and shift the zero-frequency component to the center
fft_shift <- function(mat) {
  # Swaps quadrants of a matrix
  rows <- nrow(mat)
  cols <- ncol(mat)
  r_mid <- floor(rows / 2)
  c_mid <- floor(cols / 2)

  quad1 <- mat[1:r_mid, 1:c_mid]
  quad2 <- mat[1:r_mid, (c_mid + 1):cols]
  quad3 <- mat[(r_mid + 1):rows, 1:c_mid]
  quad4 <- mat[(r_mid + 1):rows, (c_mid + 1):cols]

  rbind(cbind(quad4, quad3), cbind(quad2, quad1))
}

fft_magnitude_2d <- log(1 + Mod(fft_shift(fft_2d_result)))
```



::: notes
We create a matrix representing a white square. We then compute its 2D FFT. A crucial step for visualization is `fft_shift`, which moves the zero-frequency component from the corner (where the algorithm places it) to the center, which is more intuitive for us to view. We also take the log to compress the dynamic range for better visibility.

:::

### 2D FT Example: 2D Rect Visualization
```{r 2d_ft_plot, echo=FALSE, fig.cap="A 2D Rect (left) and its 2D Fourier Transform magnitude (right), a 2D Sinc."}
# Need to prep data for ggplot
library(reshape2)
df_img <- melt(img_matrix)
colnames(df_img) <- c("Var1", "Var2", "value")
p_img_2d <- ggplot(df_img, aes(x = Var1, y = Var2, fill = value)) +
  geom_raster() + scale_fill_gradient(low = "black", high = "white") +
  ggtitle("2D Rect Function") + theme_void() + guides(fill="none")

df_fft_2d <- melt(fft_magnitude_2d)
colnames(df_fft_2d) <- c("Var1", "Var2", "value")
p_fft_2d <- ggplot(df_fft_2d, aes(x = Var1, y = Var2, fill = value)) +
  geom_raster() + scale_fill_viridis_c() +
  ggtitle("2D FT Magnitude (2D Sinc)") + theme_void() + guides(fill="none")

p_img_2d + p_fft_2d
```



::: notes
Just as the 1D FT of a Rect is a Sinc, the 2D FT of a 2D Rect is a 2D Sinc. On the right, you can see the bright central lobe and the fainter side lobes extending in the kx and ky directions. This is a fundamental relationship in imaging.

:::

### The Convolution Theorem

This is one of the most powerful theorems in signal processing. It states that convolution in one domain is equivalent to multiplication in the other domain.

- **Convolution in Time/Space Domain <=> Multiplication in Frequency Domain**
  `\mathcal{F}\{x(t) * h(t)\} = X(k) \cdot H(k)`


- **Multiplication in Time/Space Domain <=> Convolution in Frequency Domain**
  `\mathcal{F}\{x(t) \cdot h(t)\} = X(k) * H(k)`




::: notes
This theorem is a huge deal. Convolution is a computationally expensive operation (that big integral). Multiplication is extremely fast for a computer. The convolution theorem allows us to replace a slow convolution with two FFTs, a single multiplication, and an inverse FFT. This is the basis for fast filtering algorithms used in every imaging modality.

:::

### Module 1 Summary

- Signals can be continuous or discrete.
- We use standard functions (Rect, Sinc, Delta) as building blocks.
- LSI (Linear and Shift-Invariant) systems are predictable and easy to analyze.


### Module 1 Summary
- **Convolution** describes the output of any LSI system.
- The **Fourier Transform** moves a signal between the time and frequency domains.
- The **Convolution Theorem** provides a fast way to compute convolutions.



::: notes
We have laid the entire groundwork for the course. Make sure you are comfortable with these concepts before we move on to stochastic systems, where things get a bit less predictable.

:::

## Module 2: Stochastic Systems



::: notes
Now we move from the predictable world of deterministic signals to the unpredictable world of stochastic processes. Noise is a fundamental component of all medical images, and understanding its properties is critical to evaluating and improving image quality.

:::

### Deterministic vs. Stochastic

- **Deterministic System:** The same input always produces the exact same output. The systems in Module 1 were all deterministic.
- **Stochastic System:** The output has some element of randomness. The output is described by probability distributions, not by a single, definite function.
- **Noise** is the primary source of stochastic behavior in medical imaging.




::: notes
In the real world, no system is truly deterministic. There's always some random fluctuation. In this module, we will learn how to characterize and quantify that randomness.

:::

### Major Noise Types in Medical Imaging

- **Poisson Noise (Quantum Noise):** Arises from the discrete nature of particles (e.g., photons, radioactive decays). It's signal-dependent.
- **Gaussian Noise (Electronic Noise):** Arises from thermal fluctuations in electronic components. It's generally signal-independent.
- **Rician Noise:** Found in MRI, resulting from the combination of a real signal with Gaussian noise in two orthogonal channels.



::: notes
We will focus on Poisson and Gaussian noise as they are the most common and form the basis for understanding more complex noise models.

:::

### Poisson Noise: The Math

The Poisson distribution describes the probability of a given number of events occurring in a fixed interval if these events occur with a known constant mean rate.

$$ P(k; \lambda) = \frac{\lambda^k e^{-\lambda}}{k!} $$

- `λ` (lambda) is the mean number of events.
- In imaging, `λ` is the expected number of photons.
- A key property: **The variance is equal to the mean (`σ² = λ`)**.



::: notes
This is the noise of counting statistics. If you expect to detect an average of 100 photons in a pixel, the standard deviation of that measurement will be the square root of 100, which is 10. This signal-dependent nature is a defining feature.

:::

### Poisson Noise: Code Example
```{r poisson_code, echo=TRUE}
# Generate data from a Poisson distribution
mean_photons <- 25
num_samples <- 10000

# Use rpois to generate random deviates
poisson_data <- rpois(num_samples, lambda = mean_photons)

df_poisson <- data.frame(Counts = poisson_data)

# Calculate sample mean and variance
sample_mean <- mean(poisson_data)
sample_variance <- var(poisson_data)
```



::: notes
We use R's `rpois` function to simulate `r num_samples` measurements from a process with a mean of `r mean_photons` photons. We then calculate the mean and variance to check if they are approximately equal, as the theory predicts.

:::

### Poisson Noise: Visualization
```{r poisson_plot, echo=FALSE, fig.cap="Histogram of samples from a Poisson distribution."}
ggplot(df_poisson, aes(x = Counts)) +
  geom_histogram(binwidth = 1, fill = "skyblue", color = "black", aes(y = ..density..)) +
  ggtitle(paste0("Poisson Distribution (λ = ", mean_photons, ")")) +
  labs(subtitle = paste0("Sample Mean ≈ ", round(sample_mean, 2),
                         ", Sample Variance ≈ ", round(sample_variance, 2)),
       x = "Photon Counts", y = "Density") +
  theme_minimal()
```



::: notes
As you can see, the distribution is centered around our mean of 25. The subtitle confirms the core property of Poisson noise: the sample mean is very close to the sample variance.

:::

### Gaussian Noise: The Math

The Gaussian (or Normal) distribution is described by its mean (`μ`) and standard deviation (`σ`).

$$ f(x | \mu, \sigma^2) = \frac{1}{\sqrt{2\pi\sigma^2}} e^{ - \frac{ (x - \mu)^2 }{ 2\sigma^2 } } $$

- This is the classic "bell curve."
- In contrast to Poisson noise, the variance (`σ²`) is independent of the mean signal (`μ`).



::: notes
This noise is additive and constant. It comes from the electronics in the imaging chain. Whether the signal is bright or dark, the amount of electronic noise added is generally the same.

:::

### Gaussian Noise: Code Example
```{r gaussian_code, echo=TRUE}
# Generate data from a Gaussian distribution
mean_signal <- 50
noise_std_dev <- 10
num_samples <- 10000

# Use rnorm to generate random deviates
gaussian_data <- rnorm(num_samples, mean = mean_signal, sd = noise_std_dev)

df_gaussian <- data.frame(Value = gaussian_data)
```



::: notes
Here we use `rnorm` to simulate `r num_samples` measurements. The key difference is that we explicitly define both the mean and the standard deviation, as they are independent parameters.

:::

### Gaussian Noise: Visualization
```{r gaussian_plot, echo=FALSE, fig.cap="Histogram of samples from a Gaussian distribution."}
ggplot(df_gaussian, aes(x = Value)) +
  geom_histogram(bins = 50, fill = "salmon", color = "black", aes(y = ..density..)) +
  stat_function(fun = dnorm, args = list(mean = mean_signal, sd = noise_std_dev), color = "blue", size = 1) +
  ggtitle(paste0("Gaussian Distribution (μ = ", mean_signal, ", σ = ", noise_std_dev, ")")) +
  theme_minimal()
```



::: notes
The histogram perfectly follows the classic bell curve shape, overlaid in blue. This is characteristic of electronic noise in detectors.

:::

### Noise Appearance: Poisson vs. Gaussian

- **Poisson noise is signal-dependent:** Brighter areas are noisier.
- **Gaussian noise is signal-independent:** Noise is constant everywhere.


### Noise Appearance: Visualization Code

```{r noise_appearance_code, echo=TRUE}
# Create a signal that varies in brightness (a ramp)
t_ramp <- 1:256
signal_ramp <- t_ramp

# Add Poisson noise (variance = mean)
noise_poisson <- rpois(256, lambda = signal_ramp)

# Add Gaussian noise (constant variance)
noise_gaussian <- rnorm(256, mean = signal_ramp, sd = 10)

df_ramp_p <- data.frame(Time = t_ramp, Value = noise_poisson, Type = "Poisson")
df_ramp_g <- data.frame(Time = t_ramp, Value = noise_gaussian, Type = "Gaussian")
```

### Noise Appearance: Visualization Plot
```{r noise_appearance_plot, echo=FALSE, fig.cap="Comparison of Poisson and Gaussian noise on a ramp signal."}
p_p <- ggplot(df_ramp_p, aes(x=Time, y=Value)) + geom_line() + ggtitle("Poisson Noise") + ylim(0,300)
p_g <- ggplot(df_ramp_g, aes(x=Time, y=Value)) + geom_line() + ggtitle("Gaussian Noise") + ylim(0,300)
p_p + p_g
```

### Noise Appearance: Visualization Plot (cont.)
- Notice how the Poisson noise gets much larger as the signal gets brighter (right side of the plot), while the Gaussian noise has a constant "fuzziness" across the entire signal.

### Signal-to-Noise Ratio (SNR)

SNR is the most fundamental metric of image quality. It quantifies how strong the signal is relative to the background noise.

$$ \text{SNR} = \frac{\text{Mean Signal}}{\text{Standard Deviation of Noise}} = \frac{\mu}{\sigma} $$

- A higher SNR means a cleaner, more reliable measurement.



::: notes
SNR is the currency of imaging. We are constantly trading other parameters—like scan time or radiation dose—to improve SNR. An SNR of 1 means the noise is as strong as the signal, making the signal very hard to detect.

:::

### Contrast-to-Noise Ratio (CNR)

CNR measures the ability to distinguish between two different regions or tissues, taking into account the noise level.

$$ \text{CNR} = \frac{|\text{Mean}_A - \text{Mean}_B|}{\sqrt{\sigma_A^2 + \sigma_B^2}} $$

- `A` and `B` are two regions of interest.
- High CNR is essential for detecting pathology. An object can have high contrast, but if the noise is too high, CNR will be low and it will be invisible.



::: notes
While SNR tells you about the quality in one area, CNR tells you about your ability to tell two areas apart. This is often more clinically relevant. Can I distinguish this tumor from the surrounding healthy tissue? That is a CNR question.

:::

### CNR: Visualization Code
```{r cnr_code, echo=TRUE}
# Create two regions with different means but the same noise
N_pixels <- 256 * 256
img <- matrix(rnorm(N_pixels, mean = 50, sd = 20), nrow=256, ncol=256)

# Create a signal region (A) and a background region (B)
mean_A <- 60
mean_B <- 50
img[100:156, 100:156] <- rnorm(57*57, mean = mean_A, sd = 20)
```



::: notes
We create a noisy background image. Then, we insert a square patch in the middle that has a slightly higher mean value but the same level of noise. We will now visualize this to see if we can detect the square.

:::

### CNR: Visualization Plot
```{r cnr_plot, echo=FALSE, fig.cap="Image with a square of higher signal. Its detectability is determined by CNR."}
df_cnr_img <- melt(img)
colnames(df_cnr_img) <- c("Var1", "Var2", "value")
ggplot(df_cnr_img, aes(x=Var1, y=Var2, fill=value)) +
  geom_raster() +
  scale_fill_viridis_c() +
  theme_void() +
  ggtitle(paste0("Can you see the square? (CNR ≈ ", round((mean_A - mean_B)/20, 2), ")")) +
  guides(fill="none")
```



::: notes
Whether or not you can easily see the square depends on the CNR. If we increase the difference in means or decrease the noise, the square becomes more obvious. This leads us to our next topic...

:::

### The Rose Criterion

How much CNR do you need? The Rose Criterion provides a rule of thumb.

- It states that a CNR (or SNR for a simple detection task) of approximately **5** is required for a human observer to reliably detect a signal against a noisy background.

- This is not a hard physical law, but a widely accepted psychophysical guideline.




::: notes
This is a very practical rule. If your calculated CNR for a lesion is only 1 or 2, a radiologist is very likely to miss it. We need to design our imaging systems and protocols to ensure the CNR for the targets of interest exceeds this threshold of 5.

:::

### Rose Criterion: Visualization

- Let's visualize the same object at different CNR levels.
- The object is a faint circle in the center of the image.


### Rose Criterion: Visualization Code

```{r rose_criterion_code, echo=TRUE}
create_cnr_image <- function(cnr) {
  bg_mean <- 100
  noise_sd <- 20
  signal_mean <- bg_mean + cnr * noise_sd

  img <- matrix(rnorm(128*128, mean=bg_mean, sd=noise_sd), nrow=128, ncol=128)

  # Add a circular object in the center
  x <- seq(-1, 1, length.out = 128)
  coords <- expand.grid(x = x, y = x)
  img[coords$x^2 + coords$y^2 < 0.3^2] <- rnorm(sum(coords$x^2 + coords$y^2 < 0.3^2), mean=signal_mean, sd=noise_sd)

  return(img)
}

img_cnr1 <- create_cnr_image(1)
img_cnr3 <- create_cnr_image(3)
img_cnr5 <- create_cnr_image(5)
```

### Rose Criterion: Visualization Plots
```{r rose_criterion_plots, echo=FALSE, fig.cap="Same object at CNR=1 (left), CNR=3 (middle), and CNR=5 (right)."}
p1 <- ggplot(melt(img_cnr1), aes(x=Var1, y=Var2, fill=value)) + geom_raster() + theme_void() + ggtitle("CNR = 1") + guides(fill="none") + scale_fill_viridis_c()
p3 <- ggplot(melt(img_cnr3), aes(x=Var1, y=Var2, fill=value)) + geom_raster() + theme_void() + ggtitle("CNR = 3") + guides(fill="none") + scale_fill_viridis_c()
p5 <- ggplot(melt(img_cnr5), aes(x=Var1, y=Var2, fill=value)) + geom_raster() + theme_void() + ggtitle("CNR = 5") + guides(fill="none") + scale_fill_viridis_c()

p1 + p3 + p5
```

### Rose Criterion: Visualization Plots (cont.)
- At CNR=1, the object is nearly invisible. At CNR=3, you might see it if you look closely. At CNR=5, it is clearly detectable, confirming the Rose Criterion.

### Pop Quiz!

An image region has a mean of 100 and a standard deviation of 25. What is its SNR?

A) 100
B) 25
C) 4
D) 0.25



::: notes
Answer: C) 4.
SNR = Mean / Std Dev = 100 / 25 = 4. According to the Rose Criterion, this signal would be detectable, but perhaps not with high confidence.

:::

### Noise Power Spectrum (NPS)

The NPS (also called the Wiener Spectrum) describes the frequency content of the noise.

- It is the Fourier Transform of the noise autocorrelation function.
- In simpler terms: it tells you how much noise power is present at each spatial frequency.
- `NPS(k_x, k_y)`



::: notes
Just like a signal has a frequency spectrum, the noise in an image also has a frequency spectrum. The NPS is a critical tool for characterizing the texture and correlation of noise.

:::

### NPS: Concept Visualization

- **White Noise:** Has a flat NPS. The noise power is equal at all spatial frequencies. This is typical for uncorrelated noise.
- **Colored Noise:** Has a non-flat NPS. This indicates that the noise is correlated. For example, noise might be stronger at lower frequencies. This is common after image filtering or reconstruction.




::: notes
Think of "white light," which has all colors (frequencies) equally. "White noise" has all spatial frequencies equally. If an image is blurry, it's because high frequencies have been removed. If the *noise* is blurry, it means the high-frequency components of the noise have been removed, leading to a non-flat NPS that drops off at high frequencies.

:::

### NPS: Visualization Code

```{r nps_code, echo=TRUE}
# Generate a 1D white noise signal
white_noise <- rnorm(1024)
nps_white <- Mod(fft(white_noise))^2 / length(white_noise)

# Generate colored noise by filtering white noise (e.g., a simple moving average)
colored_noise <- stats::filter(white_noise, rep(1/5, 5), sides=2)
# Remove NAs introduced by filter at the edges
colored_noise <- colored_noise[!is.na(colored_noise)]
nps_colored <- Mod(fft(colored_noise))^2 / length(colored_noise)

freq_axis_nps <- 1:length(nps_white)
df_nps <- data.frame(
  Frequency = freq_axis_nps,
  White = nps_white,
  Colored = c(nps_colored, rep(NA, length(nps_white) - length(nps_colored)))
)
```

### NPS: Visualization Plot
```{r nps_plot, echo=FALSE, fig.cap="NPS of white noise (flat) vs. colored noise (low-pass)."}
df_nps_melt <- melt(df_nps, id.vars="Frequency", variable.name="Type", value.name="Power")

ggplot(df_nps_melt, aes(x=Frequency, y=Power, color=Type)) +
  geom_line() +
  ggtitle("Noise Power Spectrum (NPS)") +
  xlim(0, length(nps_white) / 2) + # Show only first half of spectrum
  theme_minimal()
```

### NPS: Visualization Plot (cont.)
- The white noise has a relatively flat spectrum. The colored (filtered) noise has much less power at high frequencies.

### Detective Quantum Efficiency (DQE)

DQE is one of the most comprehensive metrics for assessing detector performance. It measures how efficiently a system transfers the SNR from its input to its output.

$$ \text{DQE}(k) = \frac{\text{SNR}_{\text{out}}^2(k)}{\text{SNR}_{\text{in}}^2(k)} $$


### Detective Quantum Efficiency (DQE)
- It is a function of spatial frequency, `k`.
- A perfect detector would have DQE(k) = 1 for all frequencies. This is impossible.
- DQE tells us how much of the information present in the incoming x-ray signal is actually captured and preserved in the final image.



::: notes
DQE is the gold standard for detector characterization. It combines the effects of signal response, noise (NPS), and resolution (MTF). A high DQE means the detector is very good at producing a high-quality image with minimal dose.

:::

### Module 2 Summary

- **Stochastic Systems** involve randomness, primarily from noise.
- **Poisson Noise** is signal-dependent (variance = mean).
- **Gaussian Noise** is signal-independent.


### Module 2 Summary
- **SNR** and **CNR** are key metrics for quantifying image quality.
- The **Rose Criterion** suggests a CNR of ~5 is needed for reliable detection.


### Module 2 Summary
- **NPS** describes the frequency content of noise.
- **DQE** is a comprehensive measure of detector efficiency.



::: notes
We've now covered the unpredictable aspects of imaging. We understand where noise comes from, how to describe it, and how to measure its impact on image quality. Next, we will combine our knowledge of deterministic systems and stochastic noise to understand how tomographic images are formed.

:::

## Module 3: Tomography



::: notes
Welcome to Module 3. Tomography is the process of creating a cross-sectional image from projection data. This is the physical and mathematical basis for CT, PET, and SPECT imaging. We will explore how we can reconstruct a 2D image from a series of 1D measurements.

:::

### The Core Problem of Tomography

- **Forward Problem:** If we have an object, we can predict the measurements (projections) we will get from it. This is relatively easy.
- **Inverse Problem:** If we have a set of measurements (projections), can we reconstruct the original object? This is hard, and it's the fundamental challenge of tomography.


### The Core Problem of Tomography
- The answer is yes, under certain conditions, thanks to the mathematics we will explore.



::: notes
Imagine you have a semi-transparent object. You shine a light through it from many different angles and measure the shadows it casts. Tomographic reconstruction is the art of figuring out the internal structure of the object just by looking at those shadows.

:::

### Creating a Phantom: Code
First, we need an object to "image." We will synthetically create a simplified version of the Shepp-Logan phantom, which is a standard test object in medical imaging.

### Creating a Phantom: Code (cont.)
```{r phantom_code, echo=TRUE}
# Create a simple phantom: a large circle with smaller circles inside
create_phantom <- function(n = 256) {
  phantom <- matrix(0, nrow = n, ncol = n)
  x <- seq(-1, 1, length.out = n)
  y <- seq(-1, 1, length.out = n)
  coords <- expand.grid(x = x, y = y)

  # Large background ellipse
  phantom[coords$x^2 + coords$y^2 < 0.8^2] <- 0.5

  # Two smaller high-density circles (e.g., bone)
  phantom[(coords$x - 0.3)^2 + (coords$y - 0.2)^2 < 0.1^2] <- 1
  phantom[(coords$x + 0.3)^2 + (coords$y - 0.2)^2 < 0.1^2] <- 1

  # One smaller low-density circle (e.g., lesion)
  phantom[(coords$x)^2 + (coords$y + 0.4)^2 < 0.2^2] <- 0.1

  return(phantom)
}

phantom_image <- create_phantom()
```



::: notes
We are not loading any data. Instead, we write a function that generates a 2D matrix and mathematically "draws" circles on it to represent different structures within our phantom. This gives us a known ground truth to test our reconstruction algorithms against.

:::

### Creating a Phantom: Visualization
```{r phantom_plot, echo=FALSE, fig.cap="A simple, synthetically generated Shepp-Logan style phantom."}
df_phantom <- melt(phantom_image)
colnames(df_phantom) <- c("Var1", "Var2", "value")
ggplot(df_phantom, aes(x=Var1, y=Var2, fill=value)) +
  geom_raster() +
  scale_fill_viridis_c(option = "cividis") +
  theme_void() +
  ggtitle("Synthetic Phantom Image") +
  guides(fill="none") +
  coord_fixed()
```



::: notes
Here is our test object. It's a simple representation of a head-like structure with a gray matter background, two high-density bone-like objects, and a low-density lesion-like object. Our goal is to reconstruct this image after only measuring its projections.

:::

### The Radon Transform: Math

The Radon Transform is the mathematical formalization of taking a projection. It describes the process of integrating a 2D function `f(x,y)` along a line.

$$ p(s, \theta) = \mathcal{R}\{f(x,y)\} = \int_{-\infty}^{\infty} f(s \cos\theta - u \sin\theta, s \sin\theta + u \cos\theta) du $$

- `p(s, θ)` is the projection at an angle `θ` and a distance `s` from the origin.
- This is the value of one point in the **sinogram**.



::: notes
This equation looks complex, but it's just a line integral. For a fixed angle `θ`, we are summing up all the pixel values along lines that are a distance `s` from the center. A CT scanner physically performs this integration by shining X-rays through the patient.

:::

### Simulating Projections: Code
We can't do a true continuous Radon Transform, but we can simulate it for a few discrete angles by rotating our phantom image and summing the columns.

### Simulating Projections: Code (cont.)
```{r projection_code, echo=TRUE}
# Simulate projections at a few angles
angles <- seq(0, 179, by = 45)
projections <- list()

# Convert the matrix to a magick image object once
# magick expects a 3D array (height, width, channels), so we reshape the 2D matrix
phantom_array <- array(phantom_image, dim = c(nrow(phantom_image), ncol(phantom_image), 1))
phantom_magick <- image_read(phantom_array)

for (i in 1:length(angles)) {
  # `magick` is used for rotation
  img_rot <- image_rotate(phantom_magick, angles[i])

  # Crop the image back to the original dimensions to handle resizing during rotation
  geom_string <- paste0(nrow(phantom_image), "x", ncol(phantom_image), "+0+0^")
  img_rot_cropped <- image_crop(img_rot, geom_string, gravity = "center")

  # Extract the pixel data back into a matrix
  rot_matrix <- as.numeric(image_data(img_rot_cropped, channels = "gray"))
  dim(rot_matrix) <- dim(phantom_image)

  # Sum the columns to get the 1D projection
  projections[[i]] <- colSums(rot_matrix)
}
```



::: notes
Here, we use a helper library to rotate our phantom image to different angles (0, 45, 90, 135 degrees). After each rotation, we simply sum the values in each column. This simulates a parallel-beam X-ray detector array measuring the total attenuation along each path.

:::

### Simulating Projections: Visualization
```{r projection_plot, echo=FALSE, fig.cap="1D projections of the phantom at different angles."}
df_proj <- data.frame()
for (i in 1:length(angles)) {
  temp_df <- data.frame(
    Position = 1:length(projections[[i]]),
    Value = projections[[i]],
    Angle = as.factor(angles[i])
  )
  df_proj <- rbind(df_proj, temp_df)
}

ggplot(df_proj, aes(x = Position, y = Value, color = Angle)) +
  geom_line(size=1) +
  facet_wrap(~Angle, ncol = 2, scales="free_y") +
  ggtitle("1D Projections at Different Angles") +
  theme_minimal()
```



::: notes
Each plot shows the 1D "shadow" the phantom casts at that specific angle. You can see how the shape of the projection changes dramatically with the angle, encoding information about the object's internal structure.

:::

### The Sinogram

A sinogram is the collection of all 1D projections stacked together as an image.

- The y-axis represents the angle `θ` (from 0 to 180 degrees).
- The x-axis represents the detector position `s`.
- A single point in the object traces out a sinusoidal path in the sinogram. Hence the name.



::: notes
The sinogram is the raw data of a CT scanner. It's the domain where the measurement physically happens. The job of a reconstruction algorithm is to turn this sinogram back into a meaningful cross-sectional image.

:::

### Sinogram Visualization: Code
Let's generate a more complete sinogram with more angles to get a better visual.

### Sinogram Visualization: Code (cont.)
```{r sinogram_code, echo=TRUE}
# We'll use a package that has a Radon transform function for a better sinogram
# Let's try to find one, otherwise we'll generate a fake one for visualization.
# After a quick check, there isn't a simple, dependency-free one.
# So, we generate a representative synthetic sinogram.

n_angles <- 180
n_detectors <- 256
sino_matrix <- matrix(0, nrow = n_angles, ncol = n_detectors)
s_vals <- seq(-1, 1, length.out=n_detectors)
theta_vals <- seq(0, pi, length.out=n_angles)

# Simulate the sinsusoids from the three main objects
# Parameters are tweaked to look like a real sinogram of our phantom
sino_matrix <- sino_matrix + outer(theta_vals, s_vals, function(t,s) 10*exp(-( (s - 0.3*sin(t+pi/4))^2)/0.01) )
sino_matrix <- sino_matrix + outer(theta_vals, s_vals, function(t,s) 10*exp(-( (s + 0.3*sin(t+pi/4))^2)/0.01) )
sino_matrix <- sino_matrix + outer(theta_vals, s_vals, function(t,s) -5*exp(-( (s - 0.4*cos(t))^2)/0.04) )
```



::: notes
Since performing a full, accurate Radon transform is complex, we are generating a *synthetic* sinogram for visualization purposes. We are mathematically creating the sinusoidal patterns that our phantom's features would produce. This lets us see what a real sinogram looks like.

:::

### Sinogram Visualization: Plot
```{r sinogram_plot, echo=FALSE, fig.cap="A synthetic sinogram."}
df_sino <- melt(sino_matrix)
colnames(df_sino) <- c("Angle", "Detector", "Value")

ggplot(df_sino, aes(x = Detector, y = Angle, fill = Value)) +
  geom_raster() +
  scale_fill_viridis_c() +
  ggtitle("Synthetic Sinogram") +
  labs(y = "Angle (theta)", x = "Detector Position (s)") +
  theme_minimal()
```



::: notes
This is a sinogram. Each of the bright sine waves corresponds to one of the high-density objects in our phantom. The wider, darker sine wave corresponds to the low-density object. All the information required to reconstruct the image is encoded here.

:::

### The Fourier Slice Theorem

How do we get from the sinogram back to the image? The Fourier Slice Theorem is the theoretical key.

- It states that the **1D Fourier Transform of a projection at angle `θ`** is equal to a **slice through the 2D Fourier Transform of the object at that same angle `θ`**.

- `P(k, θ) = F(k cosθ, k sinθ)`




::: notes
This is a profound and powerful link. It connects the 1D measurements we can actually make (the projections) to the 2D frequency spectrum of the object we want to reconstruct. This theorem is the foundation of the most common reconstruction algorithm: filtered backprojection.

:::

### Fourier Slice Theorem: Conceptual Diagram

```{r fst_diagram, echo=FALSE, fig.cap="Illustration of the Fourier Slice Theorem."}
# Create a representation of a 2D Fourier space
k_space <- expand.grid(kx = seq(-1, 1, by=0.1), ky = seq(-1, 1, by=0.1))

# Define a slice at a 30-degree angle
angle_rad <- 30 * pi / 180
slice <- data.frame(kx = seq(-1, 1, length.out=100) * cos(angle_rad),
                    ky = seq(-1, 1, length.out=100) * sin(angle_rad))

ggplot() +
  geom_tile(data = k_space, aes(x=kx, y=ky), fill="gray80", color="white") +
  geom_line(data=slice, aes(x=kx, y=ky), color="red", size=2) +
  labs(title="Fourier Slice Theorem",
       subtitle="The 1D FT of a projection at angle θ... is a slice through the 2D FT at the same angle.",
       x="kx", y="ky") +
  coord_fixed() +
  theme_minimal()
```
### Simple Backprojection: The Intuition

The most naive way to reconstruct the image is "simple backprojection."

- For each projection, "smear" the values back across the image at the angle from which they were acquired.
- Sum up all these smeared-back projections.
- Intuitive, but deeply flawed.



::: notes
Think of it as reversing the projection process. If a detector at one position measured a high value, we assume that high value must have come from somewhere along the line that hit that detector. So we draw that line on our blank image canvas. We do this for all projections and hope the true image emerges.

:::

### Backprojection: The "Star Artifact"

Simple backprojection doesn't work perfectly. It produces a characteristic blurring, often called a "star artifact" or "1/r blurring."

- High-frequency information (sharp edges) is lost.
- The resulting image is a blurry version of the original.
- `f_blurry(x,y) = f(x,y) * (1/r)`, where `$r = \\sqrt{x^2 + y^2}$`.



::: notes
The smearing process intrinsically adds a blur. Each point in the original object gets smeared out into a star-like shape in the reconstructed image. The final image is the true image convolved with this blurring function.

:::

### Backprojection: Visualization Code
Let's simulate backprojecting just our two projections at 0 and 90 degrees to see the smearing.

### Backprojection: Visualization Code (cont.)
```{r backprojection_code, echo=TRUE}
recon_size <- length(projections[[1]])
recon_image <- matrix(0, nrow = recon_size, ncol = recon_size)

# Backproject the 0-degree projection (vertical smearing)
proj_0 <- projections[[which(angles == 0)]]
for (i in 1:recon_size) {
  recon_image[, i] <- recon_image[, i] + proj_0
}

# Backproject the 90-degree projection (horizontal smearing)
proj_90 <- projections[[which(angles == 90)]]
for (i in 1:recon_size) {
  recon_image[i, ] <- recon_image[i, ] + proj_90
}
```



::: notes
We start with a blank image. First, we take the 0-degree projection and add its values to every row in the corresponding columns. This is the vertical "smearing." Then we take the 90-degree projection and add its values to every column in the corresponding rows (horizontal smearing).

:::

### Backprojection: Visualization Plot
```{r backprojection_plot, echo=FALSE, fig.cap="Simple backprojection of just two angles, showing the characteristic smearing."}
df_recon <- melt(recon_image)
colnames(df_recon) <- c("Var1", "Var2", "value")
ggplot(df_recon, aes(x=Var1, y=Var2, fill=value)) +
  geom_raster() +
  scale_fill_viridis_c() +
  theme_void() +
  ggtitle("Simple Backprojection (2 Angles)") +
  coord_fixed()
```



::: notes
The result is a crude, blurry outline of the original phantom. You can see the vertical and horizontal smearing. If we added more angles, the image would get less streaky and more blurry, eventually converging on that 1/r blurred version of the true object.

:::

### The Need for the Ramp Filter

How do we fix the blur from backprojection? We need to "un-blur" the image.

- Since `f_blurry = f * (1/r)`, we need to convolve with the inverse of `(1/r)`.
- The Fourier Transform of `1/r` is `1/|k|`.
- To deconvolve, we multiply in the frequency domain by the inverse, which is `|k|`.
- This `|k|` filter is called a **Ramp Filter**.




::: notes
This is the key insight. Simple backprojection gets the low-frequency information right but suppresses the high frequencies. To correct this, we need to boost the high frequencies before or during backprojection. The ramp filter does exactly that. Its shape, `|k|`, looks like a ramp, hence the name.

:::

### The Ramp Filter: Visualization
```{r ramp_filter_plot, echo=FALSE, fig.cap="The Ramp Filter in the frequency domain."}
k <- seq(-1, 1, length.out = 1000)
ramp_filter <- abs(k)
df_ramp <- data.frame(Frequency = k, Value = ramp_filter)

ggplot(df_ramp, aes(x = Frequency, y = Value)) +
  geom_line(size = 1.5, color = "blue") +
  ggtitle("The |k| Ramp Filter") +
  xlab("Spatial Frequency (k)") +
  ylab("Filter Magnitude") +
  theme_minimal()
```

### The Ramp Filter: Visualization (cont.)
- The filter multiplies low frequencies near `k=0` by almost zero, and linearly boosts the higher frequencies.

### Filtered Backprojection (FBP)

This leads to the most common analytical reconstruction algorithm: Filtered Backprojection (FBP).

1.  Measure all the 1D projections `p(s, θ)`.
2.  Take the 1D FT of each projection to get `P(k, θ)`.
3.  Multiply each `P(k, θ)` by the ramp filter `|k|`.


### Filtered Backprojection (FBP)
4.  Take the inverse 1D FT of the result.
5.  Backproject these "filtered" projections.

- This algorithm is fast, robust, and used in almost every commercial CT scanner.



::: notes
This is the complete recipe for CT reconstruction. The "filtering" step, which corrects for the backprojection blur, is the crucial addition that makes the whole process work.

:::

### Iterative Reconstruction

FBP is great, but it struggles with noisy or incomplete data. **Iterative Reconstruction** is an alternative approach.

- **Basic Idea:**
  1. Start with an initial guess for the image (e.g., a blank image).
  2. Use the Forward Model to simulate what the projections *would* look like from your guess.


### Iterative Reconstruction
  3. Compare these simulated projections to the *actual* measured projections.
  4. Update your image guess to reduce the error between the simulated and real projections.
  5. Repeat until the error is small.



::: notes
Iterative methods are like a game of "guess and check." You start with a guess, see how well it matches your data, and then intelligently improve your guess. This process is much slower than FBP but can produce better images in challenging situations, like low-dose CT.

:::

### Algebraic Formulation (Ax = b)

The iterative problem can be formulated with linear algebra.

- `x`: A vector containing all the pixel values of the image we want to find.
- `b`: A vector containing all the measured projection data.


### Algebraic Formulation (Ax = b)
- `A`: The "System Matrix." A massive matrix where each row describes how the pixel values in `x` contribute to a single measurement in `b`.


### Algebraic Formulation (Ax = b)
- The goal is to solve the system of linear equations `Ax = b` for `x`.



::: notes
For any realistic image size, the matrix A is far too enormous to solve by direct inversion. This is why we must use iterative algorithms like MLEM to find an approximate solution.

:::

### MLEM (Maximum Likelihood Expectation Maximization)

- MLEM is a popular iterative algorithm, especially in PET and SPECT.


### MLEM (Maximum Likelihood Expectation Maximization)
- It's based on finding the image `x` that is most likely to have produced the measured data `b`, assuming Poisson statistics.


### MLEM (Maximum Likelihood Expectation Maximization)
- It has the desirable property of conserving counts and ensuring pixel values remain non-negative.



::: notes
We won't go into the details of the MLEM update equation, but the key takeaway is that it's an iterative method that is particularly well-suited to the Poisson noise statistics found in nuclear medicine.

:::

### Module 3 Summary

- **Tomography** is the process of reconstructing an object from its projections.
- The **Radon Transform** is the mathematics of creating projections.
- A **Sinogram** is the collection of all projections.


### Module 3 Summary
- **Simple Backprojection** is intuitive but creates a blurry image (`1/r` blurring).
- **Filtered Backprojection (FBP)** uses a **Ramp Filter** to correct the blur and is the standard algorithm.
- **Iterative Methods** (like MLEM) are an alternative that can handle noise better but are computationally slower.



::: notes
We now understand the fundamental principles of how a CT scanner works, from data acquisition (projections) to the final image (reconstruction). In the final module, we will touch on more advanced applications and modern topics that build on these foundations.

:::

## Module 4: Advanced Applications



::: notes
In this final module, we will briefly touch upon several advanced topics and other imaging modalities. The goal is not to cover them in exhaustive detail, but to show how the fundamental concepts of signals, systems, and transforms that we've learned apply across all of medical imaging.

:::

### Magnetic Resonance Imaging (MRI)

- MRI does not use ionizing radiation.


### Magnetic Resonance Imaging (MRI)
- It uses a powerful magnetic field, radiofrequency (RF) pulses, and magnetic field gradients to create images.


### Magnetic Resonance Imaging (MRI)
- The raw data collected in an MRI scan is not a projection, but a direct measurement of the object's frequency spectrum.



::: notes
MRI is one of the most direct applications of the Fourier Transform in medical imaging. The scanner literally "collects" the Fourier space of the patient's tissues.

:::

### K-Space

- In MRI, the 2D Fourier space of the image is called **k-space**.


### K-Space
- The scanner fills k-space line by line according to a specific "pulse sequence."


### K-Space
- The final image is simply the inverse 2D Fourier Transform of the collected k-space data.

$$ \text{Image}(x,y) = \mathcal{F}^{-1}\{ \text{k-space}(k_x, k_y) \} $$



::: notes
This is a critical concept. The center of k-space contains the low-frequency information (overall contrast and brightness). The periphery of k-space contains the high-frequency information (edges and fine details).

:::

### K-Space Filtering: Code
Let's use our phantom image to simulate what happens when we manipulate k-space. We'll take the 2D FT of our phantom to get its k-space, then try filtering it.

### K-Space Filtering: Code (cont.)
```{r kspace_filter_code, echo=TRUE}
# We already have our phantom image and its 2D FT from Module 1 & 3
# Let's re-calculate k-space (the shifted FT) for clarity
kspace_full <- fft_shift(fft(phantom_image))

# Create a low-pass filter (keep the center, zero out the periphery)
center_fraction <- 0.2
kspace_lowpass <- kspace_full
rows <- nrow(kspace_lowpass)
cols <- ncol(kspace_lowpass)
r_mid <- floor(rows/2)
c_mid <- floor(cols/2)
r_keep <- floor(rows * center_fraction / 2)
c_keep <- floor(cols * center_fraction / 2)
mask_low <- matrix(0, rows, cols)
mask_low[(r_mid-r_keep):(r_mid+r_keep), (c_mid-c_keep):(c_mid+c_keep)] <- 1
kspace_lowpass <- kspace_lowpass * mask_low

# Create a high-pass filter (zero out the center, keep the periphery)
kspace_highpass <- kspace_full * (1 - mask_low)

# Inverse FFT to get the images back
# Remember to shift back before inverse FFT!
img_lowpass <- Mod(fft(fft_shift(kspace_lowpass), inverse = TRUE))
img_highpass <- Mod(fft(fft_shift(kspace_highpass), inverse = TRUE))
```



::: notes
Here we calculate the k-space of our phantom. We create a mask to isolate the center of k-space. For the low-pass filter, we multiply by this mask to keep only the center. For the high-pass filter, we multiply by the inverse of the mask. Then we perform the inverse FT to see the resulting images.

:::

### K-Space Filtering: Visualization
```{r kspace_filter_plot, echo=FALSE, fig.cap="Effect of low-pass (center) and high-pass (right) filtering in k-space."}
p_orig <- ggplot(melt(phantom_image), aes(x=Var1, y=Var2, fill=value)) + geom_raster() + theme_void() + ggtitle("Original") + guides(fill="none") + scale_fill_viridis_c(option="cividis")

p_low <- ggplot(melt(img_lowpass), aes(x=Var1, y=Var2, fill=value)) + geom_raster() + theme_void() + ggtitle("Low-Pass (Blur)") + guides(fill="none") + scale_fill_viridis_c(option="cividis")

p_high <- ggplot(melt(img_highpass), aes(x=Var1, y=Var2, fill=value)) + geom_raster() + theme_void() + ggtitle("High-Pass (Edges)") + guides(fill="none") + scale_fill_viridis_c(option="cividis")

p_orig + p_low + p_high
```



::: notes
The results perfectly illustrate the properties of k-space.
- **Original:** Our clear phantom.
- **Low-Pass:** Keeping only the center of k-space removes the high frequencies, resulting in a blurry image that only preserves the basic contrast.
- **High-Pass:** Keeping only the periphery of k-space removes the low frequencies, resulting in an image that only shows the sharp edges.

:::

### Discussion Question

A patient moves during an MRI scan. This corrupts the data being acquired at that moment. If the motion occurs while the *center* of k-space is being acquired, what is the likely artifact on the final image?



::: notes
Answer: Widespread blurring or "ghosting" artifacts. The center of k-space holds the most signal energy and determines the overall contrast of the image. Corrupting this data has a severe, global impact on the image quality, much more so than corrupting the periphery.

:::

### Ultrasound Imaging

- Uses high-frequency sound waves and their echoes to create images.


### Ultrasound Imaging
- The core principle is **beamforming**.


### Ultrasound Imaging
- **Beamforming:** By introducing microscopic time delays to the signals from individual elements in a transducer array, a focused ultrasound beam can be formed and steered electronically.



::: notes
Ultrasound is a beautiful example of using time-shifting and superposition—core concepts from our systems analysis—to physically shape and direct energy.

:::

### Delay and Sum Beamforming

- **Transmission:** A pulse is sent from each transducer element, but with slightly different start times (delays). The wavefronts from all elements interfere constructively at a desired focal point.
- **Reception:** The returning echo hits each element at a slightly different time. By applying the reverse delays to the received signals and summing them, the system can "listen" preferentially from that same focal point.




::: notes
This "delay and sum" process is a form of spatial filtering. It allows the ultrasound machine to scan a beam through the tissue to build up an image line by line, all without any moving parts.

:::

### Beamforming: Conceptual Diagram

```{r beamforming_diagram, echo=FALSE, fig.cap="Diagram of delay-and-sum beamforming to focus a wave."}
elements <- data.frame(x = seq(-2, 2, by=1), y=0)
focal_point <- data.frame(x=0, y=-4)

# Create arcs representing wavefronts
wavefronts <- data.frame()
for (i in 1:nrow(elements)) {
  dist <- sqrt((elements$x[i] - focal_point$x)^2 + (elements$y[i] - focal_point$y)^2)
  delay <- max(sqrt((elements$x - focal_point$x)^2 + (elements$y - focal_point$y)^2)) - dist
  for(r in seq(0.5, 4, by=0.5)) {
    wavefronts <- rbind(wavefronts, data.frame(x0=elements$x[i], y0=elements$y[i], r=r, delay=delay))
  }
}

ggplot() +
  geom_point(data=elements, aes(x=x, y=y), size=5, shape=22, fill="blue") +
  geom_point(data=focal_point, aes(x=x, y=y), size=5, color="red", shape=8) +
  ggforce::geom_circle(data=wavefronts, aes(x0=x0, y0=y0, r=r), color="gray") +
  coord_fixed(ylim=c(-5,1)) +
  theme_void() +
  ggtitle("Ultrasound Beamforming", subtitle="Outer elements fire earlier to create a focused wavefront.")
```
### Modern Topics: Compressed Sensing

- A relatively new paradigm in signal acquisition.
- **Core Idea:** If a signal is **sparse** in some domain (meaning most of its values are zero), it can be reconstructed from far fewer measurements than required by traditional sampling theory (Nyquist theorem).
- For example, many medical images are sparse in the wavelet domain.




::: notes
Compressed Sensing (CS) has had a huge impact on MRI. It allows us to intentionally undersample k-space (i.e., scan faster) and then use a sophisticated non-linear reconstruction algorithm to recover a high-quality image. It breaks the old rules of sampling, but only if the signal has a sparse structure.

:::

### Sparsity: Conceptual Diagram
```{r sparsity_diagram, echo=FALSE, fig.cap="A non-sparse signal (left) and a sparse signal (right)."}
# Non-sparse signal (e.g., sine wave)
df_dense <- data.frame(x=1:100, y=sin(seq(0,10,length.out=100)))

# Sparse signal (e.g., a few spikes)
df_sparse <- data.frame(x=1:100, y=0)
df_sparse$y[c(10, 30, 80)] <- c(1, -0.8, 0.9)

p_d <- ggplot(df_dense, aes(x=x, y=y)) + geom_line() + ggtitle("Non-Sparse Signal")
p_s <- ggplot(df_sparse, aes(x=x, y=y)) + geom_bar(stat="identity") + ggtitle("Sparse Signal")

p_d + p_s
```

### Sparsity: Conceptual Diagram (cont.)
- A sparse signal is one where most of the values are zero (or very close to it). Compressed sensing works by finding a transform domain where the signal becomes sparse.

### Modern Topics: Deep Learning

- Deep Learning, particularly Convolutional Neural Networks (CNNs), has revolutionized medical image analysis.


### Modern Topics: Deep Learning
- A CNN is a type of neural network that uses convolution as its primary operation.


### Modern Topics: Deep Learning
- Instead of using a fixed filter (like a ramp filter or a smoothing filter), a CNN **learns** the optimal filter kernels directly from training data to perform a specific task.



::: notes
Think back to our convolution examples. We designed a simple averaging filter for denoising. A CNN might learn thousands of different, complex filter shapes that are perfectly optimized for removing a specific type of noise from a CT image, or for highlighting the texture of a tumor. They are essentially "learned filters."

:::

### The Role of CNNs

CNNs are used for a huge variety of tasks:
- **Image Reconstruction:** Learned alternatives to FBP or iterative methods.
- **Denoising:** Learning to remove noise more effectively than traditional filters.
- **Segmentation:** Automatically outlining organs or tumors.
- **Classification:** Diagnosing whether a lesion is benign or malignant.




::: notes
The field is moving incredibly quickly, but the core mathematical operations inside these complex networks are still convolutions and non-linear transformations—concepts that are extensions of the material we have covered in this course.

:::

### CNN Architecture: Conceptual Diagram
```{r cnn_diagram, echo=FALSE, fig.cap="A simplified conceptual diagram of a Convolutional Neural Network (CNN) for image reconstruction."}
# Define the layers of the CNN
layers <- data.frame(
  x = c(1, 2, 3, 4, 5, 6),
  y = c(2, 2, 2, 2, 2, 2),
  label = c("Input\n(Undersampled\nImage)", "Conv + ReLU", "Conv + ReLU", "...", "Final Conv", "Output\n(Reconstructed\nImage)"),
  size = c(10, 8, 8, 2, 8, 10),
  color = c("blue", "red", "red", "white", "red", "green")
)

# Create the plot
ggplot(layers, aes(x = x, y = y, label = label)) +
  geom_point(aes(size = size, color = color), shape = 15) + # Use squares for layers
  geom_text(vjust = 2.5, size = 3) +
  geom_segment(data = data.frame(x = 1:5, xend = 2:6), aes(x = x, y = 2, xend = xend, yend = 2), arrow = arrow(length = unit(0.3, "cm")), inherit.aes = FALSE) +
  scale_size_continuous(range = c(20, 40)) +
  theme_void() +
  theme(legend.position = "none") +
  ggtitle("Basic CNN Structure for Image Reconstruction")

```

### CNN Architecture: Conceptual Diagram (cont.)
- **Input Layer:** Takes the corrupted/undersampled image.
- **Hidden Layers:** A series of convolutional layers (often with non-linear activation functions like ReLU) extract features and learn the image structure.
- **Output Layer:** Produces the final, high-quality reconstructed image.

### Course Summary

- **Module 1:** We defined deterministic signals and LSI systems, and established convolution and the Fourier Transform as our core analytical tools.
- **Module 2:** We introduced the reality of stochastic systems, characterizing noise and its impact on image quality through metrics like SNR and DQE.


### Course Summary
- **Module 3:** We applied these tools to understand tomography, the process of image reconstruction from projections, using algorithms like FBP.
- **Module 4:** We saw how these fundamental concepts extend to other modalities like MRI and form the basis for modern techniques like compressed sensing and deep learning.


::: notes
Congratulations on completing the course. You now have the foundational knowledge to understand the physics and mathematics behind virtually any medical imaging system.

:::